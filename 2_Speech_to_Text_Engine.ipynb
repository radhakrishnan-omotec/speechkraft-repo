{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radhakrishnan-omotec/speechkraft-repo/blob/main/2_Speech_to_Text_Engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOoccGXSJdYx"
      },
      "source": [
        "# Speech to Text Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlRdiRNlJdY0"
      },
      "source": [
        "Python code represents a Speech Recognition Engine implemented on a Raspberry Pi microcontroller. Utilizing the SpeechRecognition library, PyAudio, and pyttsx3, the system captures user speech through an integrated microphone, transcribes it to text using Google's Speech Recognition service, and generates synthesized speech responses. The code serves as a foundation for integrating a Language Model (LLM) to analyze and enhance user interactions, offering capabilities such as sentence completion, synonym suggestions, and corrections. The user experience involves a dynamic interplay between spoken input and synthesized output, demonstrating the potential for advanced voice-based applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M47csAfJdY1"
      },
      "source": [
        "*Initialization*: The code initializes a SpeechRecognitionEngine class, incorporating a speech recognizer, a microphone, a text-to-speech (TTS) engine (pyttsx3), and the PyAudio library for audio functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOlg2gE-JdY1",
        "outputId": "0b292445-7d61-4e33-ba52-8d7c2fcbcdf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyttsx3 in c:\\users\\omolp091\\anaconda3\\lib\\site-packages (2.90)\n",
            "Requirement already satisfied: pywin32 in c:\\users\\omolp091\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
            "Requirement already satisfied: pypiwin32 in c:\\users\\omolp091\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
            "Requirement already satisfied: comtypes in c:\\users\\omolp091\\anaconda3\\lib\\site-packages (from pyttsx3) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyttsx3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkGJXa1sJdY4",
        "outputId": "19ae3699-d385-460b-9dee-377097a7b7d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyAudio in c:\\users\\omolp091\\anaconda3\\lib\\site-packages (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyAudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkEEeHgmJdY4",
        "outputId": "013b0a1f-ced7-4c68-f47b-41fc0cd8bc5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeechRecognition in c:\\users\\omolp091\\anaconda3\\lib\\site-packages (3.10.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\users\\omolp091\\anaconda3\\lib\\site-packages (from SpeechRecognition) (2.28.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\omolp091\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\omolp091\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\omolp091\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omolp091\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\omolp091\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ8CQBMNJdY4"
      },
      "outputs": [],
      "source": [
        "import speech_recognition as sr\n",
        "import pyttsx3\n",
        "import pyaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbNVzCLkJdY5"
      },
      "source": [
        "### The SpeechRecognitionEngine class:\n",
        "This serves as an interface for capturing user speech, converting it to text, and generating synthesized speech outputs, making it a versatile tool for speech-based applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gVYuMIMJdY5"
      },
      "source": [
        "1. The constructor initializes key components: a speech recognizer (recognizer), a microphone (microphone), a text-to-speech engine (speaker), and an audio interface (audio). These components enable the class to capture audio, transcribe speech, and generate synthesized speech."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AllLccd7JdY6"
      },
      "source": [
        "2. *Capture Audio*: The `capture_audio` method uses the microphone to capture user speech. It adjusts for ambient noise and returns the audio data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D7jDMxKJdY6"
      },
      "source": [
        "3. *Speech to Text*: The `speech_to_text` method transcribes the captured audio into text using the Google Speech Recognition API. It handles unknown value errors and request errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSKogGdmJdY6"
      },
      "source": [
        "4. *Text to Speech*: The `text_to_speech` method converts the LLM model outputs or any text into speech, utilizing the TTS engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kqFv64HJdY7"
      },
      "outputs": [],
      "source": [
        "class SpeechRecognitionEngine:\n",
        "    def __init__(self):\n",
        "        self.recognizer = sr.Recognizer()\n",
        "        self.microphone = sr.Microphone()\n",
        "        self.speaker = pyttsx3.init()\n",
        "        self.audio = pyaudio.PyAudio()\n",
        "        self.listening = True\n",
        "\n",
        "    def announce(self, message):\n",
        "        self.speaker.say(message)\n",
        "        self.speaker.runAndWait()\n",
        "\n",
        "    def capture_audio(self):\n",
        "        with self.microphone as source:\n",
        "            print(\"Listening...\")\n",
        "            self.recognizer.adjust_for_ambient_noise(source)\n",
        "            audio_data = self.recognizer.listen(source)\n",
        "        return audio_data\n",
        "\n",
        "    def speech_to_text(self, audio_data):\n",
        "        try:\n",
        "            print(\"Transcribing...\")\n",
        "            text = self.recognizer.recognize_google(audio_data)\n",
        "            print(f\"User's speech: {text}\")\n",
        "            return text\n",
        "        except sr.UnknownValueError:\n",
        "            print(\"Speech recognition could not understand audio\")\n",
        "            return None\n",
        "        except sr.RequestError as e:\n",
        "            print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
        "            return None\n",
        "\n",
        "    def text_to_speech(self, output_text):\n",
        "        print(f\"Output: {output_text}\")\n",
        "        self.speaker.say(output_text)\n",
        "        self.speaker.runAndWait()\n",
        "\n",
        "    def stop_listen(self, text):\n",
        "        return text and \"stop\" in text.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lUyi1xuJdY7"
      },
      "source": [
        "5. *Main Code*: The main loop continuously captures user speech, transcribes it, and processes it using the LLM model. The LLM model outputs are then displayed and spoken back to the user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPjJhmp5JdY8",
        "outputId": "a7a75f3f-280c-4f41-8426-f8844ce9f656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listening...\n",
            "Transcribing...\n",
            "User's speech: text message\n",
            "Listening...\n",
            "Transcribing...\n",
            "User's speech: my first text message\n",
            "Listening...\n",
            "Transcribing...\n",
            "Speech recognition could not understand audio\n",
            "Listening...\n",
            "Transcribing...\n",
            "Speech recognition could not understand audio\n",
            "Listening...\n",
            "Transcribing...\n",
            "User's speech: cartoon aap Dal sakte hain vah Badal Sakte to understand whether we can improve\n",
            "Listening...\n",
            "Transcribing...\n",
            "Speech recognition could not understand audio\n",
            "Listening...\n",
            "Transcribing...\n",
            "User's speech: WhatsApp\n",
            "Listening...\n",
            "Transcribing...\n",
            "Speech recognition could not understand audio\n",
            "Listening...\n",
            "Transcribing...\n",
            "Speech recognition could not understand audio\n",
            "Listening...\n",
            "Transcribing...\n",
            "Speech recognition could not understand audio\n",
            "Listening...\n",
            "Transcribing...\n",
            "User's speech: Vijay Ganesha ne bola tha ki preparation of charge and presentation values that can but before that try to see what are the\n",
            "Listening...\n",
            "Transcribing...\n",
            "Speech recognition could not understand audio\n",
            "Listening...\n",
            "Transcribing...\n",
            "Speech recognition could not understand audio\n",
            "Listening...\n",
            "Transcribing...\n",
            "User's speech: text message\n",
            "Listening...\n",
            "Transcribing...\n",
            "Speech recognition could not understand audio\n",
            "Listening...\n",
            "Transcribing...\n",
            "Speech recognition could not understand audio\n",
            "Listening...\n",
            "Transcribing...\n",
            "User's speech: stop stop\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    speech_engine = SpeechRecognitionEngine()\n",
        "\n",
        "    while speech_engine.listening:\n",
        "        user_audio = speech_engine.announce(\"Start Speaking\")\n",
        "\n",
        "        user_audio = speech_engine.capture_audio()\n",
        "        user_text = speech_engine.speech_to_text(user_audio)\n",
        "\n",
        "        if speech_engine.stop_listen(user_text):\n",
        "            speech_engine.listening = False\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}